{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4243451,"sourceType":"datasetVersion","datasetId":32526}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom transformers import GPT2Tokenizer, GPT2Model\nimport pandas as pd\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:25:39.305896Z","iopub.execute_input":"2024-12-11T02:25:39.306547Z","iopub.status.idle":"2024-12-11T02:26:03.135987Z","shell.execute_reply.started":"2024-12-11T02:25:39.306513Z","shell.execute_reply":"2024-12-11T02:26:03.135038Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"file=\"/kaggle/input/news-category-dataset/News_Category_Dataset_v3.json\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:03.137518Z","iopub.execute_input":"2024-12-11T02:26:03.138056Z","iopub.status.idle":"2024-12-11T02:26:03.143110Z","shell.execute_reply.started":"2024-12-11T02:26:03.138025Z","shell.execute_reply":"2024-12-11T02:26:03.142201Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import json\n\ndef process_file(file_path):\n  news = []\n  with open(file_path, 'r') as file:\n          for line in file:\n              json_object = json.loads(line)\n              news.append(json_object)\n  return news\n\nnews = process_file(file)\nprint(len(news))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:03.144231Z","iopub.execute_input":"2024-12-11T02:26:03.144566Z","iopub.status.idle":"2024-12-11T02:26:04.905851Z","shell.execute_reply.started":"2024-12-11T02:26:03.144529Z","shell.execute_reply":"2024-12-11T02:26:04.904898Z"}},"outputs":[{"name":"stdout","text":"209527\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import random\n# Take 10% subset\nsubset_size = int(0.1 * len(news))  # Calculate 10% of the data\nrandom.shuffle(news)  # Shuffle the data\nsubset = news[:subset_size]  # Take the first `subset_size` entries\n\n# Output\nprint(f\"Total news objects: {len(news)}\")\nprint(f\"Subset size: {len(subset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:04.907615Z","iopub.execute_input":"2024-12-11T02:26:04.907928Z","iopub.status.idle":"2024-12-11T02:26:05.037048Z","shell.execute_reply.started":"2024-12-11T02:26:04.907884Z","shell.execute_reply":"2024-12-11T02:26:05.036231Z"}},"outputs":[{"name":"stdout","text":"Total news objects: 209527\nSubset size: 20952\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":" \n\ntext_cat_pairs = []\n\nfor news_item in subset:\n    headline = news_item.get(\"headline\")\n    short_description = news_item.get(\"short_description\")\n    text = headline + \" || \" + short_description\n    category = news_item.get(\"category\")\n    text_cat_pairs.append((text, category))\n\ntext_cat_pairs[5]\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:05.038211Z","iopub.execute_input":"2024-12-11T02:26:05.038602Z","iopub.status.idle":"2024-12-11T02:26:05.083292Z","shell.execute_reply.started":"2024-12-11T02:26:05.038556Z","shell.execute_reply":"2024-12-11T02:26:05.082477Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('Steve Scalise Readmitted To ICU In Serious Condition Over Concerns Of Infection || The GOP whip had been previously upgraded to \"fair condition\" and moved out of the ICU.',\n 'POLITICS')"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"label_to_index = {}\nindex_to_label = {}\ni = 0\n\n# Assuming text_cat_pairs is a list of labels or a list of (text, label) pairs\nfor text, label in text_cat_pairs:\n    if label not in label_to_index:\n        label_to_index[label] = i\n        index_to_label[i] = label\n        i += 1\n\n# Outputs\nprint(\"Label to Index Mapping:\", label_to_index)\nprint(\"Index to Label Mapping:\", index_to_label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:05.084278Z","iopub.execute_input":"2024-12-11T02:26:05.084525Z","iopub.status.idle":"2024-12-11T02:26:05.100087Z","shell.execute_reply.started":"2024-12-11T02:26:05.084501Z","shell.execute_reply":"2024-12-11T02:26:05.099214Z"}},"outputs":[{"name":"stdout","text":"Label to Index Mapping: {'WELLNESS': 0, 'PARENTING': 1, 'STYLE & BEAUTY': 2, 'TRAVEL': 3, 'HEALTHY LIVING': 4, 'POLITICS': 5, 'BUSINESS': 6, 'ENTERTAINMENT': 7, 'STYLE': 8, 'SPORTS': 9, 'THE WORLDPOST': 10, 'QUEER VOICES': 11, 'WOMEN': 12, 'WORLD NEWS': 13, 'WEIRD NEWS': 14, 'WEDDINGS': 15, 'FOOD & DRINK': 16, 'ENVIRONMENT': 17, 'HOME & LIVING': 18, 'ARTS': 19, 'ARTS & CULTURE': 20, 'IMPACT': 21, 'GREEN': 22, 'PARENTS': 23, 'FIFTY': 24, 'DIVORCE': 25, 'MEDIA': 26, 'COLLEGE': 27, 'U.S. NEWS': 28, 'COMEDY': 29, 'CRIME': 30, 'TASTE': 31, 'GOOD NEWS': 32, 'BLACK VOICES': 33, 'WORLDPOST': 34, 'TECH': 35, 'EDUCATION': 36, 'RELIGION': 37, 'LATINO VOICES': 38, 'MONEY': 39, 'SCIENCE': 40, 'CULTURE & ARTS': 41}\nIndex to Label Mapping: {0: 'WELLNESS', 1: 'PARENTING', 2: 'STYLE & BEAUTY', 3: 'TRAVEL', 4: 'HEALTHY LIVING', 5: 'POLITICS', 6: 'BUSINESS', 7: 'ENTERTAINMENT', 8: 'STYLE', 9: 'SPORTS', 10: 'THE WORLDPOST', 11: 'QUEER VOICES', 12: 'WOMEN', 13: 'WORLD NEWS', 14: 'WEIRD NEWS', 15: 'WEDDINGS', 16: 'FOOD & DRINK', 17: 'ENVIRONMENT', 18: 'HOME & LIVING', 19: 'ARTS', 20: 'ARTS & CULTURE', 21: 'IMPACT', 22: 'GREEN', 23: 'PARENTS', 24: 'FIFTY', 25: 'DIVORCE', 26: 'MEDIA', 27: 'COLLEGE', 28: 'U.S. NEWS', 29: 'COMEDY', 30: 'CRIME', 31: 'TASTE', 32: 'GOOD NEWS', 33: 'BLACK VOICES', 34: 'WORLDPOST', 35: 'TECH', 36: 'EDUCATION', 37: 'RELIGION', 38: 'LATINO VOICES', 39: 'MONEY', 40: 'SCIENCE', 41: 'CULTURE & ARTS'}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"  index_to_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:05.101290Z","iopub.execute_input":"2024-12-11T02:26:05.101670Z","iopub.status.idle":"2024-12-11T02:26:05.114443Z","shell.execute_reply.started":"2024-12-11T02:26:05.101633Z","shell.execute_reply":"2024-12-11T02:26:05.113741Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{0: 'WELLNESS',\n 1: 'PARENTING',\n 2: 'STYLE & BEAUTY',\n 3: 'TRAVEL',\n 4: 'HEALTHY LIVING',\n 5: 'POLITICS',\n 6: 'BUSINESS',\n 7: 'ENTERTAINMENT',\n 8: 'STYLE',\n 9: 'SPORTS',\n 10: 'THE WORLDPOST',\n 11: 'QUEER VOICES',\n 12: 'WOMEN',\n 13: 'WORLD NEWS',\n 14: 'WEIRD NEWS',\n 15: 'WEDDINGS',\n 16: 'FOOD & DRINK',\n 17: 'ENVIRONMENT',\n 18: 'HOME & LIVING',\n 19: 'ARTS',\n 20: 'ARTS & CULTURE',\n 21: 'IMPACT',\n 22: 'GREEN',\n 23: 'PARENTS',\n 24: 'FIFTY',\n 25: 'DIVORCE',\n 26: 'MEDIA',\n 27: 'COLLEGE',\n 28: 'U.S. NEWS',\n 29: 'COMEDY',\n 30: 'CRIME',\n 31: 'TASTE',\n 32: 'GOOD NEWS',\n 33: 'BLACK VOICES',\n 34: 'WORLDPOST',\n 35: 'TECH',\n 36: 'EDUCATION',\n 37: 'RELIGION',\n 38: 'LATINO VOICES',\n 39: 'MONEY',\n 40: 'SCIENCE',\n 41: 'CULTURE & ARTS'}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import torch\n\ndef convert_labels(label):\n  return torch.tensor(label_to_index[label])\n\n\nlabels = [cat for (text, cat) in text_cat_pairs]\nprint(labels[5])\nprint(convert_labels(labels[5]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:05.115328Z","iopub.execute_input":"2024-12-11T02:26:05.115540Z","iopub.status.idle":"2024-12-11T02:26:05.199373Z","shell.execute_reply.started":"2024-12-11T02:26:05.115519Z","shell.execute_reply":"2024-12-11T02:26:05.198400Z"}},"outputs":[{"name":"stdout","text":"POLITICS\ntensor(5)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Generate the labels\nlabels = [convert_labels(label) for _, label in text_cat_pairs]\nstacked_tensors_y = torch.tensor(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:05.200355Z","iopub.execute_input":"2024-12-11T02:26:05.200640Z","iopub.status.idle":"2024-12-11T02:26:05.334062Z","shell.execute_reply.started":"2024-12-11T02:26:05.200613Z","shell.execute_reply":"2024-12-11T02:26:05.333197Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"stacked_tensors_y = stacked_tensors_y.long()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:05.338752Z","iopub.execute_input":"2024-12-11T02:26:05.339227Z","iopub.status.idle":"2024-12-11T02:26:05.343995Z","shell.execute_reply.started":"2024-12-11T02:26:05.339192Z","shell.execute_reply":"2024-12-11T02:26:05.342897Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2Model\n\n# Load the GPT-2 tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nembedding_model = GPT2Model.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:05.345154Z","iopub.execute_input":"2024-12-11T02:26:05.345456Z","iopub.status.idle":"2024-12-11T02:26:11.401468Z","shell.execute_reply.started":"2024-12-11T02:26:05.345420Z","shell.execute_reply":"2024-12-11T02:26:11.400533Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36cfd418277c40f291e0592b211e128c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec99f5bd9b334b8ca44a2b66c4a7addd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e764d5ba11f549deab3dbbff6e1dce8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddcbbfd6bbd141b89ab3581f3f8031c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af0f9539988f4f449bd3035134888068"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e70161ee0b4775ae378160fbd3c4c1"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import torch\n\ndef embed_sentence_with_padding(sentence, max_length=128, device=None):\n     \n\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    inputs = tokenizer(\n        sentence,\n        return_tensors='pt',\n        padding='max_length',\n        truncation=True,\n        max_length=max_length\n    ).to(device)  # Move inputs to the device\n\n    with torch.no_grad():\n        outputs = embedding_model(**inputs)  # Move model and outputs to the device\n        embeddings = outputs.last_hidden_state.to(device)\n    return embeddings.view(embeddings.size(1), -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:11.402669Z","iopub.execute_input":"2024-12-11T02:26:11.403028Z","iopub.status.idle":"2024-12-11T02:26:11.409611Z","shell.execute_reply.started":"2024-12-11T02:26:11.402997Z","shell.execute_reply":"2024-12-11T02:26:11.408603Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nembedding_model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:11.410825Z","iopub.execute_input":"2024-12-11T02:26:11.411239Z","iopub.status.idle":"2024-12-11T02:26:11.938707Z","shell.execute_reply.started":"2024-12-11T02:26:11.411210Z","shell.execute_reply":"2024-12-11T02:26:11.937827Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"GPT2Model(\n  (wte): Embedding(50257, 768)\n  (wpe): Embedding(1024, 768)\n  (drop): Dropout(p=0.1, inplace=False)\n  (h): ModuleList(\n    (0-11): 12 x GPT2Block(\n      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (attn): GPT2SdpaAttention(\n        (c_attn): Conv1D(nf=2304, nx=768)\n        (c_proj): Conv1D(nf=768, nx=768)\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPT2MLP(\n        (c_fc): Conv1D(nf=3072, nx=768)\n        (c_proj): Conv1D(nf=768, nx=3072)\n        (act): NewGELUActivation()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"def generate_embeddings_in_batches(text_cat_pairs, batch_size=100):\n    all_embeddings = []\n    for i in range(0, len(text_cat_pairs), batch_size):\n        batch = text_cat_pairs[i:i + batch_size]\n        batch_embeddings = [embed_sentence_with_padding(text,max_length=128) for text, _ in batch]\n        all_embeddings.extend(batch_embeddings)\n    return all_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:26:11.939782Z","iopub.execute_input":"2024-12-11T02:26:11.940064Z","iopub.status.idle":"2024-12-11T02:26:11.945321Z","shell.execute_reply.started":"2024-12-11T02:26:11.940038Z","shell.execute_reply":"2024-12-11T02:26:11.944455Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"all_embeddings = generate_embeddings_in_batches(text_cat_pairs)\n \ntorch.save(all_embeddings, 'all_embeddings.pt')\n#all_embeddings = torch.load('all_embeddings.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:27:10.180805Z","iopub.execute_input":"2024-12-11T02:27:10.181249Z","iopub.status.idle":"2024-12-11T02:30:36.556417Z","shell.execute_reply.started":"2024-12-11T02:27:10.181215Z","shell.execute_reply":"2024-12-11T02:30:36.555687Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":" len(all_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:33:27.075029Z","iopub.execute_input":"2024-12-11T02:33:27.075396Z","iopub.status.idle":"2024-12-11T02:33:27.081387Z","shell.execute_reply.started":"2024-12-11T02:33:27.075363Z","shell.execute_reply":"2024-12-11T02:33:27.080502Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"20952"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"batch_size = 100  # You can try to keep your original batch size \nstacked_tensors_x = []\n\nfor i in range(0, len(all_embeddings), batch_size):\n    batch = all_embeddings[i:i + batch_size]\n    \n    # Move the batch to CPU before stacking\n    batch = [tensor.cpu() for tensor in batch] \n    \n    torch.cuda.empty_cache()  \n    stacked_batch = torch.stack(batch)\n    stacked_tensors_x.append(stacked_batch)\n    del batch, stacked_batch  # Delete to free up memory\n\nprint(len(stacked_tensors_x))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:33:29.641813Z","iopub.execute_input":"2024-12-11T02:33:29.642194Z","iopub.status.idle":"2024-12-11T02:33:36.498523Z","shell.execute_reply.started":"2024-12-11T02:33:29.642163Z","shell.execute_reply":"2024-12-11T02:33:36.497580Z"}},"outputs":[{"name":"stdout","text":"210\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"stacked_tensors_x = torch.stack([embedding.cpu() for embedding in all_embeddings])\nprint(stacked_tensors_x.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:33:42.491533Z","iopub.execute_input":"2024-12-11T02:33:42.492194Z","iopub.status.idle":"2024-12-11T02:33:56.993358Z","shell.execute_reply.started":"2024-12-11T02:33:42.492159Z","shell.execute_reply":"2024-12-11T02:33:56.992468Z"}},"outputs":[{"name":"stdout","text":"torch.Size([20952, 128, 768])\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import random_split\n\n# Assuming you have stacked_tensors_x and stacked_tensors_y\n\n# Define the dataset\ndataset = torch.utils.data.TensorDataset(stacked_tensors_x, stacked_tensors_y)\n\n# Define the split ratios (e.g., 80% train, 10% validation, 10% test)\ntrain_ratio = 0.8\nval_ratio = 0.1\ntest_ratio = 0.1\n\n# Calculate dataset sizes\ndataset_size = len(dataset)\ntrain_size = int(train_ratio * dataset_size)\nval_size = int(val_ratio * dataset_size)\ntest_size = dataset_size - train_size - val_size\n\n# Split the dataset\ntrain_dataset, val_dataset, test_dataset = random_split(\n    dataset, [train_size, val_size, test_size]\n)\n\nprint(f\"Train dataset size: {len(train_dataset)}\")\nprint(f\"Validation dataset size: {len(val_dataset)}\")\nprint(f\"Test dataset size: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:34:12.274566Z","iopub.execute_input":"2024-12-11T02:34:12.274992Z","iopub.status.idle":"2024-12-11T02:34:12.292271Z","shell.execute_reply.started":"2024-12-11T02:34:12.274906Z","shell.execute_reply":"2024-12-11T02:34:12.291221Z"}},"outputs":[{"name":"stdout","text":"Train dataset size: 16761\nValidation dataset size: 2095\nTest dataset size: 2096\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import torch.nn as nn\n\nclass BiLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(BiLSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n                            batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_size * 2, num_classes)  # 2 for bidirection\n\n    def forward(self, x):  # Remove hidden\n        # Create hidden state inside forward method\n        batch_size = x.size(0)\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)\n\n        # Forward propagate LSTM (using provided or initialized hidden)\n        out, _ = self.lstm(x, (h0, c0))  # Update hidden\n\n        # Decode the hidden state of the last time step\n        last_hidden = self.fc(out[:, -1, :])\n        first_hidden = self.fc(out[:, 0, :])\n        output = last_hidden + first_hidden\n\n        return output  # Return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:34:16.343850Z","iopub.execute_input":"2024-12-11T02:34:16.344231Z","iopub.status.idle":"2024-12-11T02:34:16.351229Z","shell.execute_reply.started":"2024-12-11T02:34:16.344203Z","shell.execute_reply":"2024-12-11T02:34:16.350296Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\n \n\n# Hyperparameters\ninput_size = stacked_tensors_x.shape[2]  # embedding_size for GPT2 embeddings\nhidden_size = 128\nnum_layers = 2\nnum_classes = len(label_to_index)\nlearning_rate = 0.001\nnum_epochs = 20\nbatch_size = 128  # Adjust as needed\n\n# Create the model\nmodel = BiLSTM(input_size, hidden_size, num_layers, num_classes)\n\n# Move the model to the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:34:19.654598Z","iopub.execute_input":"2024-12-11T02:34:19.655385Z","iopub.status.idle":"2024-12-11T02:34:19.823633Z","shell.execute_reply.started":"2024-12-11T02:34:19.655349Z","shell.execute_reply":"2024-12-11T02:34:19.822896Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs):\n    model.to(device)\n\n    for epoch in range(num_epochs):\n        # Training Phase\n        model.train()\n        train_loss = 0\n        train_correct = 0\n        train_total = 0\n\n        for batch_idx, (data, targets) in enumerate(train_loader):\n            data = data.to(device)\n            targets = targets.to(device)\n\n            # Forward pass\n            scores = model(data)\n            loss = criterion(scores, targets)\n\n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Calculate training accuracy and loss\n            _, predicted = torch.max(scores.data, 1)\n            train_total += targets.size(0)\n            train_correct += (predicted == targets).sum().item()\n            train_loss += loss.item()\n\n        # Calculate training accuracy for the epoch\n        train_accuracy = 100 * train_correct / train_total\n\n        # Validation Phase\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for data, targets in val_loader:\n                data = data.to(device)\n                targets = targets.to(device)\n\n                # Forward pass\n                scores = model(data)\n                loss = criterion(scores, targets)\n\n                # Calculate validation accuracy and loss\n                _, predicted = torch.max(scores.data, 1)\n                val_total += targets.size(0)\n                val_correct += (predicted == targets).sum().item()\n                val_loss += loss.item()\n\n        # Calculate validation accuracy for the epoch\n        val_accuracy = 100 * val_correct / val_total\n\n        # Print epoch statistics\n        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n              f\"Train Loss: {train_loss / len(train_loader):.4f}, \"\n              f\"Train Acc: {train_accuracy:.2f}%, \"\n              f\"Val Loss: {val_loss / len(val_loader):.4f}, \"\n              f\"Val Acc: {val_accuracy:.2f}%\")\n\n    print(\"Training finished!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:34:22.470526Z","iopub.execute_input":"2024-12-11T02:34:22.471144Z","iopub.status.idle":"2024-12-11T02:34:22.480320Z","shell.execute_reply.started":"2024-12-11T02:34:22.471112Z","shell.execute_reply":"2024-12-11T02:34:22.479535Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:34:29.163274Z","iopub.execute_input":"2024-12-11T02:34:29.163626Z","iopub.status.idle":"2024-12-11T02:37:22.095250Z","shell.execute_reply.started":"2024-12-11T02:34:29.163578Z","shell.execute_reply":"2024-12-11T02:37:22.094283Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/20] - Train Loss: 2.9440, Train Acc: 26.11%, Val Loss: 2.5565, Val Acc: 34.84%\nEpoch [2/20] - Train Loss: 2.3163, Train Acc: 39.13%, Val Loss: 2.2238, Val Acc: 41.29%\nEpoch [3/20] - Train Loss: 2.0418, Train Acc: 45.06%, Val Loss: 2.0240, Val Acc: 44.34%\nEpoch [4/20] - Train Loss: 1.8345, Train Acc: 49.16%, Val Loss: 1.9231, Val Acc: 47.73%\nEpoch [5/20] - Train Loss: 1.6649, Train Acc: 53.16%, Val Loss: 1.7579, Val Acc: 52.17%\nEpoch [6/20] - Train Loss: 1.5107, Train Acc: 56.82%, Val Loss: 1.7362, Val Acc: 51.93%\nEpoch [7/20] - Train Loss: 1.3835, Train Acc: 60.22%, Val Loss: 1.6391, Val Acc: 54.18%\nEpoch [8/20] - Train Loss: 1.2656, Train Acc: 62.83%, Val Loss: 1.6159, Val Acc: 55.42%\nEpoch [9/20] - Train Loss: 1.1365, Train Acc: 66.48%, Val Loss: 1.6674, Val Acc: 54.70%\nEpoch [10/20] - Train Loss: 1.0360, Train Acc: 69.20%, Val Loss: 1.6293, Val Acc: 55.75%\nEpoch [11/20] - Train Loss: 0.9111, Train Acc: 72.95%, Val Loss: 1.6921, Val Acc: 54.46%\nEpoch [12/20] - Train Loss: 0.8121, Train Acc: 75.73%, Val Loss: 1.6987, Val Acc: 54.75%\nEpoch [13/20] - Train Loss: 0.7182, Train Acc: 78.14%, Val Loss: 1.7639, Val Acc: 54.84%\nEpoch [14/20] - Train Loss: 0.6090, Train Acc: 81.79%, Val Loss: 1.8208, Val Acc: 53.60%\nEpoch [15/20] - Train Loss: 0.5023, Train Acc: 85.08%, Val Loss: 1.9204, Val Acc: 53.79%\nEpoch [16/20] - Train Loss: 0.4136, Train Acc: 87.78%, Val Loss: 1.9738, Val Acc: 53.65%\nEpoch [17/20] - Train Loss: 0.3357, Train Acc: 90.01%, Val Loss: 2.0751, Val Acc: 53.41%\nEpoch [18/20] - Train Loss: 0.2567, Train Acc: 93.03%, Val Loss: 2.1775, Val Acc: 52.46%\nEpoch [19/20] - Train Loss: 0.2070, Train Acc: 94.50%, Val Loss: 2.3332, Val Acc: 53.03%\nEpoch [20/20] - Train Loss: 0.1550, Train Acc: 96.11%, Val Loss: 2.3886, Val Acc: 52.51%\nTraining finished!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, accuracy_score\ndef calculate_metrics(model, loader, device):\n    model.eval()\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        for data, targets in loader:\n            data = data.to(device)\n            targets = targets.to(device)\n\n            # Forward pass\n            scores = model(data)\n            _, predicted = torch.max(scores, 1)\n\n            # Collect predictions and true labels\n            all_preds.extend(predicted.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n\n    # Calculate metrics\n    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average=\"weighted\")\n    accuracy = accuracy_score(all_targets, all_preds) * 100\n\n    return {\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n        \"accuracy\": accuracy\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:37:27.052392Z","iopub.execute_input":"2024-12-11T02:37:27.052780Z","iopub.status.idle":"2024-12-11T02:37:27.059999Z","shell.execute_reply.started":"2024-12-11T02:37:27.052748Z","shell.execute_reply":"2024-12-11T02:37:27.059121Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_metrics = calculate_metrics(model, train_loader, device)\nval_metrics = calculate_metrics(model, val_loader, device)\n\nprint(\"\\nEvaluation Metrics:\")\nprint(f\"Train Precision: {train_metrics['precision']:.4f}\")\nprint(f\"Train Recall: {train_metrics['recall']:.4f}\")\nprint(f\"Train F1-Score: {train_metrics['f1']:.4f}\")\nprint(f\"Train Accuracy: {train_metrics['accuracy']:.2f}%\")\n\nprint(f\"Val Precision: {val_metrics['precision']:.4f}\")\nprint(f\"Val Recall: {val_metrics['recall']:.4f}\")\nprint(f\"Val F1-Score: {val_metrics['f1']:.4f}\")\nprint(f\"Val Accuracy: {val_metrics['accuracy']:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:37:30.011935Z","iopub.execute_input":"2024-12-11T02:37:30.012792Z","iopub.status.idle":"2024-12-11T02:37:34.951153Z","shell.execute_reply.started":"2024-12-11T02:37:30.012730Z","shell.execute_reply":"2024-12-11T02:37:34.949973Z"}},"outputs":[{"name":"stdout","text":"\nEvaluation Metrics:\nTrain Precision: 0.9827\nTrain Recall: 0.9824\nTrain F1-Score: 0.9824\nTrain Accuracy: 98.24%\nVal Precision: 0.5207\nVal Recall: 0.5251\nVal F1-Score: 0.5173\nVal Accuracy: 52.51%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def test(model, test_loader, criterion, device):\n    model.eval()  # Set model to evaluation mode\n    test_loss = 0\n    test_correct = 0\n    test_total = 0\n\n    with torch.no_grad():\n        for data, targets in test_loader:\n            data = data.to(device)\n            targets = targets.to(device)\n\n            # Forward pass\n            scores = model(data)\n            loss = criterion(scores, targets)\n\n            # Calculate test accuracy and loss\n            _, predicted = torch.max(scores.data, 1)\n            test_total += targets.size(0)\n            test_correct += (predicted == targets).sum().item()\n            test_loss += loss.item()\n\n    # Calculate test accuracy\n    test_accuracy = 100 * test_correct / test_total\n\n    print(f\"Test Loss: {test_loss / len(test_loader):.4f}, \"\n          f\"Test Accuracy: {test_accuracy:.2f}%\")\n\n    return test_loss / len(test_loader), test_accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:37:44.027575Z","iopub.execute_input":"2024-12-11T02:37:44.028258Z","iopub.status.idle":"2024-12-11T02:37:44.034935Z","shell.execute_reply.started":"2024-12-11T02:37:44.028222Z","shell.execute_reply":"2024-12-11T02:37:44.033860Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":" \ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:37:46.838383Z","iopub.execute_input":"2024-12-11T02:37:46.839079Z","iopub.status.idle":"2024-12-11T02:37:46.842906Z","shell.execute_reply.started":"2024-12-11T02:37:46.839047Z","shell.execute_reply":"2024-12-11T02:37:46.841990Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"test_loss, test_accuracy = test(model, test_loader, criterion, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:37:50.292818Z","iopub.execute_input":"2024-12-11T02:37:50.293275Z","iopub.status.idle":"2024-12-11T02:37:50.920987Z","shell.execute_reply.started":"2024-12-11T02:37:50.293241Z","shell.execute_reply":"2024-12-11T02:37:50.920097Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 2.3980, Test Accuracy: 55.92%\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"class TransformerClassifier(nn.Module):\n    def __init__(self, input_dim, num_classes, num_heads=2, dropout=0.7):  # Increased dropout\n        super(TransformerClassifier, self).__init__()\n         \n        self.transformer_encoder = torch.nn.MultiheadAttention(input_dim, num_heads,\n                                                               dropout=dropout, bias=False,\n                                                               kdim=input_dim, vdim=input_dim,\n                                                               batch_first=True)\n        \n        # Layer normalization\n        self.norm = nn.LayerNorm(input_dim)\n        \n        # Fully connected Head with dropout\n        self.fc = nn.Linear(input_dim, num_classes)\n        self.dropout = nn.Dropout(dropout)  # Added dropout layer\n\n    def forward(self, x):\n         \n        # Transformer Encoder\n        output, _ = self.transformer_encoder(x, x, x, need_weights=False)\n        # apply layer normalization\n        output = self.norm(output)\n        # take the average over all attention (hidden) states\n        output = torch.mean(output, dim=1)\n        # Apply dropout before the fully connected layer\n        output = self.dropout(output)  \n        # Fully Connected Layer for Classification\n        output = self.fc(output)\n\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:05.615151Z","iopub.execute_input":"2024-12-11T04:09:05.615567Z","iopub.status.idle":"2024-12-11T04:09:05.623295Z","shell.execute_reply.started":"2024-12-11T04:09:05.615532Z","shell.execute_reply":"2024-12-11T04:09:05.622311Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"device = torch.device('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:37:57.680712Z","iopub.execute_input":"2024-12-11T02:37:57.681191Z","iopub.status.idle":"2024-12-11T02:37:57.686147Z","shell.execute_reply.started":"2024-12-11T02:37:57.681144Z","shell.execute_reply":"2024-12-11T02:37:57.685064Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"model = TransformerClassifier(input_size, num_classes).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:05:44.205576Z","iopub.execute_input":"2024-12-11T04:05:44.205958Z","iopub.status.idle":"2024-12-11T04:05:44.228043Z","shell.execute_reply.started":"2024-12-11T04:05:44.205897Z","shell.execute_reply":"2024-12-11T04:05:44.227370Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4,weight_decay=0.04 )\ntrain(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T03:14:18.957843Z","iopub.execute_input":"2024-12-11T03:14:18.958243Z","iopub.status.idle":"2024-12-11T03:24:03.110332Z","shell.execute_reply.started":"2024-12-11T03:14:18.958210Z","shell.execute_reply":"2024-12-11T03:24:03.109386Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/50] - Train Loss: 3.3540, Train Acc: 16.97%, Val Loss: 4.1332, Val Acc: 19.81%\nEpoch [2/50] - Train Loss: 3.0750, Train Acc: 23.70%, Val Loss: 3.2804, Val Acc: 30.21%\nEpoch [3/50] - Train Loss: 2.7273, Train Acc: 32.35%, Val Loss: 2.9430, Val Acc: 35.18%\nEpoch [4/50] - Train Loss: 2.3978, Train Acc: 39.61%, Val Loss: 2.4687, Val Acc: 41.00%\nEpoch [5/50] - Train Loss: 2.0960, Train Acc: 45.18%, Val Loss: 2.1649, Val Acc: 47.35%\nEpoch [6/50] - Train Loss: 1.8501, Train Acc: 50.87%, Val Loss: 1.9937, Val Acc: 50.41%\nEpoch [7/50] - Train Loss: 1.6888, Train Acc: 54.13%, Val Loss: 1.9570, Val Acc: 50.55%\nEpoch [8/50] - Train Loss: 1.5822, Train Acc: 56.11%, Val Loss: 1.7808, Val Acc: 53.94%\nEpoch [9/50] - Train Loss: 1.5002, Train Acc: 58.16%, Val Loss: 1.7835, Val Acc: 54.08%\nEpoch [10/50] - Train Loss: 1.4369, Train Acc: 59.44%, Val Loss: 1.7158, Val Acc: 55.80%\nEpoch [11/50] - Train Loss: 1.3844, Train Acc: 60.61%, Val Loss: 1.6811, Val Acc: 56.09%\nEpoch [12/50] - Train Loss: 1.3577, Train Acc: 61.08%, Val Loss: 1.7318, Val Acc: 55.61%\nEpoch [13/50] - Train Loss: 1.3176, Train Acc: 62.15%, Val Loss: 1.6543, Val Acc: 55.80%\nEpoch [14/50] - Train Loss: 1.2693, Train Acc: 63.00%, Val Loss: 1.6516, Val Acc: 57.04%\nEpoch [15/50] - Train Loss: 1.2453, Train Acc: 63.42%, Val Loss: 1.6251, Val Acc: 57.71%\nEpoch [16/50] - Train Loss: 1.2216, Train Acc: 63.88%, Val Loss: 1.6086, Val Acc: 60.29%\nEpoch [17/50] - Train Loss: 1.1995, Train Acc: 64.54%, Val Loss: 1.6291, Val Acc: 57.57%\nEpoch [18/50] - Train Loss: 1.1804, Train Acc: 65.26%, Val Loss: 1.6645, Val Acc: 56.61%\nEpoch [19/50] - Train Loss: 1.1537, Train Acc: 65.49%, Val Loss: 1.6498, Val Acc: 58.09%\nEpoch [20/50] - Train Loss: 1.1225, Train Acc: 66.58%, Val Loss: 1.6130, Val Acc: 58.52%\nEpoch [21/50] - Train Loss: 1.0989, Train Acc: 66.93%, Val Loss: 1.6663, Val Acc: 58.28%\nEpoch [22/50] - Train Loss: 1.0918, Train Acc: 67.11%, Val Loss: 1.6421, Val Acc: 59.52%\nEpoch [23/50] - Train Loss: 1.0698, Train Acc: 67.65%, Val Loss: 1.6749, Val Acc: 58.14%\nEpoch [24/50] - Train Loss: 1.0442, Train Acc: 68.55%, Val Loss: 1.6636, Val Acc: 58.42%\nEpoch [25/50] - Train Loss: 1.0296, Train Acc: 69.07%, Val Loss: 1.7272, Val Acc: 57.76%\nEpoch [26/50] - Train Loss: 1.0107, Train Acc: 69.23%, Val Loss: 1.7650, Val Acc: 58.09%\nEpoch [27/50] - Train Loss: 1.0004, Train Acc: 69.52%, Val Loss: 1.6595, Val Acc: 59.19%\nEpoch [28/50] - Train Loss: 0.9837, Train Acc: 70.03%, Val Loss: 1.7105, Val Acc: 58.04%\nEpoch [29/50] - Train Loss: 0.9770, Train Acc: 70.34%, Val Loss: 1.7006, Val Acc: 59.71%\nEpoch [30/50] - Train Loss: 0.9495, Train Acc: 71.04%, Val Loss: 1.7076, Val Acc: 58.62%\nEpoch [31/50] - Train Loss: 0.9428, Train Acc: 71.52%, Val Loss: 1.7051, Val Acc: 59.09%\nEpoch [32/50] - Train Loss: 0.9210, Train Acc: 71.41%, Val Loss: 1.6840, Val Acc: 59.19%\nEpoch [33/50] - Train Loss: 0.9104, Train Acc: 72.07%, Val Loss: 1.7874, Val Acc: 59.14%\nEpoch [34/50] - Train Loss: 0.8887, Train Acc: 72.61%, Val Loss: 1.7792, Val Acc: 58.81%\nEpoch [35/50] - Train Loss: 0.8896, Train Acc: 72.54%, Val Loss: 1.7689, Val Acc: 58.62%\nEpoch [36/50] - Train Loss: 0.8735, Train Acc: 72.95%, Val Loss: 1.7810, Val Acc: 58.42%\nEpoch [37/50] - Train Loss: 0.8628, Train Acc: 73.24%, Val Loss: 1.8085, Val Acc: 57.80%\nEpoch [38/50] - Train Loss: 0.8383, Train Acc: 74.09%, Val Loss: 1.8334, Val Acc: 58.42%\nEpoch [39/50] - Train Loss: 0.8343, Train Acc: 74.09%, Val Loss: 1.8503, Val Acc: 57.90%\nEpoch [40/50] - Train Loss: 0.8183, Train Acc: 74.80%, Val Loss: 1.8311, Val Acc: 58.33%\nEpoch [41/50] - Train Loss: 0.8009, Train Acc: 75.12%, Val Loss: 1.8488, Val Acc: 57.71%\nEpoch [42/50] - Train Loss: 0.7912, Train Acc: 75.51%, Val Loss: 1.9051, Val Acc: 57.95%\nEpoch [43/50] - Train Loss: 0.7892, Train Acc: 75.17%, Val Loss: 1.8897, Val Acc: 58.23%\nEpoch [44/50] - Train Loss: 0.7651, Train Acc: 76.26%, Val Loss: 1.8867, Val Acc: 57.47%\nEpoch [45/50] - Train Loss: 0.7632, Train Acc: 76.15%, Val Loss: 1.9784, Val Acc: 56.42%\nEpoch [46/50] - Train Loss: 0.7496, Train Acc: 76.50%, Val Loss: 1.9098, Val Acc: 58.14%\nEpoch [47/50] - Train Loss: 0.7362, Train Acc: 76.85%, Val Loss: 1.9122, Val Acc: 58.28%\nEpoch [48/50] - Train Loss: 0.7259, Train Acc: 77.38%, Val Loss: 1.9327, Val Acc: 58.62%\nEpoch [49/50] - Train Loss: 0.7152, Train Acc: 77.36%, Val Loss: 1.9658, Val Acc: 58.00%\nEpoch [50/50] - Train Loss: 0.6979, Train Acc: 78.18%, Val Loss: 1.9784, Val Acc: 56.90%\nTraining finished!\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"train_metrics = calculate_metrics(model, train_loader, device)\nval_metrics = calculate_metrics(model, val_loader, device)\n\nprint(\"\\nEvaluation Metrics:\")\nprint(f\"Train Precision: {train_metrics['precision']:.4f}\")\nprint(f\"Train Recall: {train_metrics['recall']:.4f}\")\nprint(f\"Train F1-Score: {train_metrics['f1']:.4f}\")\nprint(f\"Train Accuracy: {train_metrics['accuracy']:.2f}%\")\n\nprint(f\"Val Precision: {val_metrics['precision']:.4f}\")\nprint(f\"Val Recall: {val_metrics['recall']:.4f}\")\nprint(f\"Val F1-Score: {val_metrics['f1']:.4f}\")\nprint(f\"Val Accuracy: {val_metrics['accuracy']:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T03:24:08.167154Z","iopub.execute_input":"2024-12-11T03:24:08.167503Z","iopub.status.idle":"2024-12-11T03:24:13.761849Z","shell.execute_reply.started":"2024-12-11T03:24:08.167473Z","shell.execute_reply":"2024-12-11T03:24:13.760738Z"}},"outputs":[{"name":"stdout","text":"\nEvaluation Metrics:\nTrain Precision: 0.7956\nTrain Recall: 0.7935\nTrain F1-Score: 0.7903\nTrain Accuracy: 79.35%\nVal Precision: 0.5566\nVal Recall: 0.5690\nVal F1-Score: 0.5548\nVal Accuracy: 56.90%\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"test_loss, test_accuracy = test(model, test_loader, criterion, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T03:24:17.539178Z","iopub.execute_input":"2024-12-11T03:24:17.539534Z","iopub.status.idle":"2024-12-11T03:24:18.231173Z","shell.execute_reply.started":"2024-12-11T03:24:17.539503Z","shell.execute_reply":"2024-12-11T03:24:18.229998Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 2.0631, Test Accuracy: 58.11%\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef predict_user_input(model, user_input, tokenizer, embedding_model, device, class_labels):\n    # Step 1: Embed the user input\n    embeddings = embed_sentence_with_padding(user_input, tokenizer, embedding_model, device=device)\n    \n    # Step 2: Get the embedding shape\n    batch_size, seq_len, embedding_dim = embeddings.size()\n    \n    # Debugging: Check the shape of the embeddings\n    print(f\"Embeddings shape: {embeddings.shape}\")  # Should be (batch_size, 128, 768)\n    \n    # Step 3: Transpose the embedding tensor for compatibility with the model\n    embeddings = embeddings.permute(0, 2, 1)  # (batch_size, embedding_dim, seq_len)\n    \n    # Now embeddings will have shape (1, 768, 128), which should match the model's expected input\n\n    # Step 4: Pass the embeddings through the classifier model\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        output = model(embeddings)  # Output shape: (batch_size, num_classes)\n    \n    # Step 5: Apply softmax to get probabilities\n    probabilities = F.softmax(output, dim=1)\n\n    # Step 6: Get the predicted class index\n    predicted_idx = torch.argmax(probabilities, dim=1).item()\n\n    # Step 7: Map the predicted index to the class label\n    predicted_class = class_labels[predicted_idx]\n\n    return predicted_class, probabilities[0][predicted_idx].item()\n\n# Example usage\nuser_input = \"Apple unveiled its latest iPhone with advanced camera features.\"\npredicted_class, confidence = predict_user_input(model, user_input, tokenizer, embedding_model, device, class_labels)\nprint(f\"Predicted class: {predicted_class} with confidence: {confidence}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:56:00.940687Z","iopub.execute_input":"2024-12-11T04:56:00.941092Z","iopub.status.idle":"2024-12-11T04:56:00.969122Z","shell.execute_reply.started":"2024-12-11T04:56:00.941057Z","shell.execute_reply":"2024-12-11T04:56:00.968193Z"}},"outputs":[{"name":"stdout","text":"Embeddings shape: torch.Size([1, 128, 768])\nPredicted class: ARTS & CULTURE with confidence: 0.03960195556282997\n","output_type":"stream"}],"execution_count":130},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}